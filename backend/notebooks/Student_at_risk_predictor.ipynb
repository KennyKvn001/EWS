{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data-Driven Early Warning and Support System for At-Risk Learners in Rwanda Higher Education programs**\n",
        "\n",
        "This notebook aim to train and evaluate a multiclass for for predicting student who are at risk, It will integrate XAI for interpretability of the prediction to get clear view why the model is producing those predictions\n",
        "\n",
        "This notebook will have different section including:\n",
        "* Exploratory Data Analysis\n",
        "* Data Preprocessing & Feature Engineering\n",
        "* Model Implementation & Optimization\n",
        "* Experiment & Trails/Result Table\n",
        "* Model Evaluation & Error Analysis"
      ],
      "metadata": {
        "id": "ii04E29DtHm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Package imports and loading dataset**"
      ],
      "metadata": {
        "id": "twmVzCRPwWYA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM7TPCyasFLK"
      },
      "outputs": [],
      "source": [
        "# Import important packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import shap\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data from the source\n",
        "dt = pd.read_csv('')\n",
        "dt.head()"
      ],
      "metadata": {
        "id": "tIy2gziUy6Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploratoty Data Analysis**"
      ],
      "metadata": {
        "id": "InaR6hYTw8Gf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dc93ecf"
      },
      "source": [
        "# General EDA steps for multiclass datasets\n",
        "\n",
        "# 1. Display basic information about the dataset\n",
        "print(\"Dataset Info:\")\n",
        "dt.info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Display descriptive statistics\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "display(dt.describe())"
      ],
      "metadata": {
        "id": "nYQLxzuDD3Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "display(dt.isnull().sum())"
      ],
      "metadata": {
        "id": "JdKZvpQ_D5HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Visualize the distribution of the target variable\n",
        "print(\"\\nTarget Variable Distribution:\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x=dt.iloc[:, -1]) # last column of the dataset\n",
        "plt.title('Distribution of Target Variable')\n",
        "plt.xlabel('Classes')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "b0DGIT01D7D9",
        "outputId": "f5727531-2f9e-4bab-939e-ef9c45d59b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target Variable Distribution:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3789471248.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTarget Variable Distribution:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# last column of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Distribution of Target Variable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Classes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dt' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preprocessing & Feature Engineering**"
      ],
      "metadata": {
        "id": "JxANNw7zxL37"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6f0390c"
      },
      "source": [
        "### **Handling Data Issues**\n",
        "\n",
        "Based on the EDA, we will handle potential issues such as class imbalance.\n",
        "\n",
        "To be done here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "hNFmnFyeGMfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06d4a5fc"
      },
      "source": [
        "### **Applying Transformations**\n",
        "\n",
        "We will apply necessary transformations to the features, such as encoding categorical variables and scaling numerical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19562c7e"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "categorical_features = # TODO\n",
        "numerical_features = # TODO\n",
        "\n",
        "# Create transformers for numerical and categorical features\n",
        "numerical_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "# Create a column transformer to apply different transformations to different columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Apply the preprocessing steps\n",
        "X_processed = # TODO\n",
        "y_processed = # TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff827f2f"
      },
      "source": [
        "### **Feature Engineering/Selection**\n",
        "\n",
        "Based on the understanding of the data and the problem, we will implement feature engineering to features as necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "940157e7"
      },
      "source": [
        "# feature engineering techniques based on previous preprocessing\n",
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4080c16d"
      },
      "source": [
        "### Preprocessing Steps\n",
        "\n",
        "Below is a summary of the preprocessing steps performed:\n",
        "\n",
        " To be done here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Implementation & Optimization**"
      ],
      "metadata": {
        "id": "RuIYZFzpyYFS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5605b9d0"
      },
      "source": [
        "### **Random Forest Model**\n",
        "\n",
        "Implementing training for Random forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc559759"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Split data into training, validation, and testing sets\n",
        "X_train, X_temp, y_train, y_temp = # TODO\n",
        "X_val, X_test, y_val, y_test = # TODO\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Validation set shape: {X_val.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}\")\n",
        "\n",
        "# Define a function for training and validating a model\n",
        "def train_and_validate_model(model, X_train, y_train, X_val, y_val, model_name):\n",
        "    \"\"\"Trains a model and performs validation.\"\"\"\n",
        "    # TODO\n",
        "\n",
        "    return\n",
        "\n",
        "# Initialize and train the Random Forest Classifier\n",
        "rf_model = # TODO\n",
        "rf_model, y_pred_val_rf = # TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9813fffa"
      },
      "source": [
        "### **Decision Tree Model**\n",
        "\n",
        "Implementing desicion tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c018925"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize and train the Decision Tree Classifier\n",
        "dt_model = # TODO\n",
        "dt_model, y_pred_val_dt = # TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "208f94b3"
      },
      "source": [
        "### **XGBoost Model**\n",
        "\n",
        "Implementing XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "836ccd3d"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize and train the XGBoost Classifier\n",
        "xgb_model = # TODO\n",
        "xgb_model, y_pred_val_xgb = # TODO\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Summary & Observitions**"
      ],
      "metadata": {
        "id": "PxS1AubCFUY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experiment & Trials/ Result Table**"
      ],
      "metadata": {
        "id": "q-K_By0lyeR7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7jDsTK-LynAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fQ4VCEo_5P-j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eccc111d"
      },
      "source": [
        "| Experiment | Model | Accuracy | Precision | Recall | F1-Score |\n",
        "|---|---|---|---|---|---|\n",
        "| Experiment 1 | Random Forest |  |  |  |  |\n",
        "| Experiment 2 | Decision Tree |  |  |  |  |\n",
        "| Experiment 3 | XGBoost |  |  |  |  |"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Evaluation & Error analysis**"
      ],
      "metadata": {
        "id": "CUbPI2Uoyqgw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cN26e6InyyGq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}